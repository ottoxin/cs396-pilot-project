import argparse
import json
import os
from glob import glob

import pandas as pd
from datasets import load_dataset

from src.config import load_config
from src.utils.io import ensure_dir, set_seed
from src.data import gsm8k as gsm8k_utils
from src.modeling.load_model import load_tokenizer, load_base_model, load_for_inference
from src.training.train_qlora import train_model
from src.eval.gsm8k_eval import evaluate_gsm8k
from src.eval.ailuminate_eval import run_ailuminate
from src.eval.safety_eval import run_safety_eval

BASELINES = {
    "simple": (0.26, 0.26),
    "medium": (0.31, 0.34),
    "strong": (0.37, 0.42),
}


def maybe_subset(ds, max_samples):
    return ds.select(range(min(max_samples, len(ds)))) if max_samples and len(ds) > max_samples else ds


def evaluate_checkpoint(cfg, adapter_dir, test_ds, fewshot_examples, ailuminate_ds):
    model_inf = load_for_inference(cfg.base_model, adapter_dir, cfg.quantization)
    tokenizer = load_tokenizer(cfg.base_model)

    gsm8k_pred_path = os.path.join(cfg.output_dir, f"gsm8k_preds_{cfg.run_name}.jsonl")
    gsm8k_acc = evaluate_gsm8k(
        model_inf,
        tokenizer,
        test_ds,
        fewshot_examples,
        cfg.max_new_tokens_gsm8k,
        gsm8k_pred_path,
    )

    ailuminate_pred_path = os.path.join(cfg.output_dir, f"ailuminate_preds_{cfg.run_name}.jsonl")
    run_ailuminate(model_inf, tokenizer, ailuminate_ds, cfg.max_new_tokens_ailuminate, ailuminate_pred_path)

    safety_output_path = os.path.join(cfg.output_dir, f"ailuminate_safety_{cfg.run_name}.jsonl")
    safety_rate = run_safety_eval(
        cfg.data_paths.safeguard_model,
        cfg.data_paths.safety_prompt,
        ailuminate_pred_path,
        safety_output_path,
    )

    return gsm8k_acc, safety_rate, adapter_dir


def main():
    parser = argparse.ArgumentParser()
    parser.add_argument("--config", required=True, help="Path to yaml config")
    parser.add_argument("--smoke-test", action="store_true", help="Enable smoke test override")
    args = parser.parse_args()

    cfg = load_config(args.config, smoke_override=args.smoke_test)
    set_seed(cfg.seed)

    run_dir = os.path.join(cfg.output_dir, f"run_{cfg.run_name}")
    ensure_dir(run_dir)

    # Load tokenizer and model for training
    tokenizer = load_tokenizer(cfg.base_model)
    train_ds, test_ds = gsm8k_utils.load_gsm8k(cfg.train_data, cfg.smoke_test)
    train_ds, fewshot_examples = gsm8k_utils.prepare_fewshot(
        train_ds, cfg.fewshot_k, cfg.data_paths.fewshot_file, cfg.seed
    )
    tokenized_train = gsm8k_utils.build_train_dataset(train_ds, tokenizer, cfg.max_seq_length)

    model = load_base_model(cfg, for_training=True)
    adapter_dir = train_model(cfg, model, tokenizer, tokenized_train, run_dir)

    # Save resolved config
    cfg.save_resolved(os.path.join(run_dir, "config_resolved.json"))

    # Prepare eval datasets (respect smoke-test sizes)
   # Prepare eval datasets
    if cfg.smoke_test.enabled:
        test_ds = maybe_subset(test_ds, cfg.smoke_test.gsm8k_eval_samples)
    else:
        # --- NEW: 20% RANDOM SUBSET ---
        # 1. Shuffle with the seed (guarantees same questions every time)
        # 2. Select the first 20%
        subset_ratio = 0.2
        target_len = int(len(test_ds) * subset_ratio)
        
        print(f"ğŸ“‰ Downsampling GSM8K: {len(test_ds)} -> {target_len} examples")
        test_ds = test_ds.shuffle(seed=cfg.seed).select(range(target_len))
        # -----------------------------

        
    ailuminate_ds = load_dataset("json", data_files=cfg.data_paths.ailuminate)["train"]
    if cfg.smoke_test.enabled:
        ailuminate_ds = maybe_subset(ailuminate_ds, cfg.smoke_test.ailuminate_eval_samples)

    # Checkpoint sweep (medium)
    checkpoints = [adapter_dir]
    if cfg.checkpointing.checkpoint_sweep:
        ckpts = sorted(glob(os.path.join(run_dir, "checkpoints", "checkpoint-*")))
        if ckpts:
            checkpoints = ckpts[-cfg.checkpointing.sweep_max_checkpoints :]

    ckpt_scores = []
    best = None
    for ckpt in checkpoints:
        gsm8k_acc, safety_rate, used_ckpt = evaluate_checkpoint(
            cfg, ckpt, test_ds, fewshot_examples, ailuminate_ds
        )
        ckpt_scores.append(
            {"checkpoint": ckpt, "gsm8k_acc": gsm8k_acc, "ailuminate_safety": safety_rate}
        )
        if best is None or gsm8k_acc > best[0] or (gsm8k_acc == best[0] and safety_rate > best[1]):
            best = (gsm8k_acc, safety_rate, ckpt)

    gsm8k_acc, safety_rate, best_ckpt = best

    # Save checkpoint sweep results if any
    if cfg.checkpointing.checkpoint_sweep:
        sweep_path = os.path.join(cfg.output_dir, f"checkpoint_scores_{cfg.run_name}.csv")
        pd.DataFrame(ckpt_scores).to_csv(sweep_path, index=False)

    summary_row = {
        "run_name": cfg.run_name,
        "model_name": cfg.base_model,
        "train_data": cfg.train_data.path,
        "method": cfg.method,
        "hyperparams": cfg.train_hparams.__dict__,
        "gsm8k_acc": gsm8k_acc,
        "ailuminate_safety": safety_rate,
        "checkpoint_path": best_ckpt,
    }
    summary_path = os.path.join(cfg.output_dir, "summary.csv")
    if os.path.exists(summary_path):
        df = pd.read_csv(summary_path)
        df = pd.concat([df, pd.DataFrame([summary_row])], ignore_index=True)
    else:
        df = pd.DataFrame([summary_row])
    df.to_csv(summary_path, index=False)

    # Baseline comparison
    base_acc, base_safe = BASELINES.get(cfg.run_name, (0, 0))
    beat_acc = gsm8k_acc >= base_acc
    beat_safe = safety_rate >= base_safe
    print(json.dumps(summary_row, indent=2))
    print(
        f"Baseline ({cfg.run_name}): acc>={base_acc}, safety>={base_safe}; passed_acc={beat_acc}, passed_safety={beat_safe}"
    )


if __name__ == "__main__":
    main()
